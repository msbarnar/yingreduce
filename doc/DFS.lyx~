#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date true
\use_refstyle 1
\boxbgcolor #faf0e6
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth -1
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Distributed File System
\end_layout

\begin_layout Author
Matthew Barnard
\end_layout

\begin_layout Section
Structure
\end_layout

\begin_layout Standard
The Distributed File System (DFS) is a key->value database distributed pseudoran
domly among a computer network.
\end_layout

\begin_layout Standard
The basic unit of storage, transmission, and accession in the system is
 the 
\emph on
page, 
\emph default
and multiple pages are related by a 
\emph on
table name
\emph default
.
 A page is an array of 
\emph on
elements
\emph default
 composed of a 
\emph on
key 
\emph default
and a 
\emph on
value
\emph default
.
 The key and value are serializable types known as 
\emph on
writable
\emph default
.
 The key is further defined as being 
\emph on
comparable
\emph default
 to other keys, so that a set of keys can be sorted naturally.
 The internal composition and structure of the keys and values is not defined,
 as long as they implement the writable interface.
\end_layout

\begin_layout Section
Input
\end_layout

\begin_layout Standard
For data to be entered into the system it must be translated from an arbitrary
 format to a set of 
\emph on
elements
\emph default
.
 This is accomplished by implementing an 
\emph on
element reader
\emph default
, which reads elements from an arbitrary source.
\end_layout

\begin_layout Standard
One node in the DFS may be provided with an element reader and will proceed
 to draw elements from it until the source is depleted or it is stopped.
 As elements are read from the source they are placed in a 
\emph on
page builder
\emph default
, which serializes them and assembles them in sequentially numbered pages
 of limited capacity.
 When a page's capacity is reached such that the next element would exceed
 its capacity, the page is 
\emph on
closed
\emph default
 and placed in a queue for distribution; simultaneously a new page is created
 and the page builder continues to accept elements.
\end_layout

\begin_layout Section
Distribution
\end_layout

\begin_layout Standard
The following process may occur concurrently some number of times according
 to system resources and pages pending distribution.
\end_layout

\begin_layout Standard
As pages arrive in the 
\emph on
distribution queue 
\emph default
on the 
\emph on
distributing node 
\emph default

\begin_inset Formula $N_{D}$
\end_inset


\emph on
, 
\emph default
their destination is determined by hashing their table name concatenated
 with their integral index, generating the page 
\emph on
key
\emph default
 
\begin_inset Formula $K$
\end_inset

.
 The underlying peer-to-peer network is queried using this key and returns
 several of the nodes most closely matching that key, in ascending order
 of distance.
 The first of these is selected as the 
\emph on
initial node
\emph default
 
\begin_inset Formula $N_{0}$
\end_inset

.
\end_layout

\begin_layout Standard
The initial node is contacted requesting that it accept a page.
 The inital node currently has no option and must receive the page; there
 is no recourse in place if that node's capacity is exceeded.
\end_layout

\begin_layout Standard
A binary reader is attached to the page in the distributing node's memory
 and is connected to a TCP stream to the initial node.
 The initial node creates a file on disk corresponding to the page's key
 and attaches an output stream to it.
 The initial node then connects the incoming TCP stream to the file output
 stream so that the page's contents are streamed directly from the distributing
 node's memory to the inital node's disk, minimizing the possibility for
 denial of memory availability when numerous large pages are sent.
\end_layout

\begin_layout Section
Replication
\end_layout

\begin_layout Standard
When the initial node has fully received the page the distributing node
 is free to dispose of it unless the distributing node is one of the top
 three closest nodes to that page's key.
 If this is the case, the node commits the page to disk so that it can be
 referenced by its key.
\end_layout

\begin_layout Standard
The initial node performs its own network query for the page's key, finding
 the top three closest nodes.
 It selects the first closest node 
\begin_inset Formula $N_{1}$
\end_inset

 besides itself and copies the page to it in the same manner as in 
\emph on
Distribution
\emph default
.
\end_layout

\begin_layout Standard
\begin_inset Formula $N_{1}$
\end_inset

 repeats this process with 
\begin_inset Formula $N_{2}$
\end_inset

 so that the three nodes most closely associated with the page's key carry
 copies of it: these nodes 
\begin_inset Formula $\{N_{0},N_{1},N_{2}\}$
\end_inset

 are the page's 
\emph on
container nodes
\emph default
.
\end_layout

\begin_layout Standard
Each of the container nodes remains in periodic contact with each of the
 other nodes.
 As soon as one node is determined to be unreachable, the remaining two
 nodes decide between themselves randomly as to who will redistribute the
 page.
 Whichever node is chosen repeats the process of finding the next nearest
 node that is not one of the two container nodes and sends the page to it;
 that node then becomes a member of the container nodes.
\end_layout

\begin_layout Section
Precision Maintenance
\end_layout

\begin_layout Standard
As nodes enter and leave the network the distribution of node keys changes.
 To ensure that a page's container nodes are always the nodes with the nearest
 keys to its key, newly joined nodes must broadcast their key and request
 and pages which more closely match the new nodes than their previous containers.
\end_layout

\begin_layout Standard
When a new node joins it queries the network for the nodes with keys nearest
 its own.
 It contacts all of these simultaneously, informing them of its key.
 Each of those nodes examines their page stores and calculates the nearness
 of each of their pages to themselves as well as the new node.
 Any pages which are closer to the new node are retrieved and queued for
 distribution to that node.
 As distirbution may take some time to complete, the new node is immediately
 informed that these nodes have those pages.
 Because the new node is close to those pages, it may receive requests for
 them despite not yet actually carrying them.
 If this happens, the node should respond to those requests with a 
\emph on
forward
\emph default
 message containing the address of the node actually carrying the page.
 As soon as the new node begins carrying a page it will cease forwarding
 requests.
\end_layout

\end_body
\end_document
